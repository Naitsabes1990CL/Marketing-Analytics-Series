{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMULATING A RCT DATA SET GENERATED FROM A DIRECT MKTING CAMPAIGN / E-COMMERCE A/B TEST ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my experience a very helpful thought experiment is to try to think about the data generating process behind a given data set. In the last few months I've been working with several randomized controlled trials data sets and quasi-experimental data sets generated by different marketing/operational process in an e-commerce platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on that experience I believe I have the enough maturity and understanding of the underlying business processes dynamics to try and generate a näive data generating process which will try to emulate the observed data distributions stemming from a typical RCT data set resulting from a marketing campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Lets define the MINIMAL OBSERVATION UNIT and start working our way from there! #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity lets assume our minimal observational unit will be a given customer, in a real-world setting, one customer can receive several pushes and incentives in the form of marketing campaigns, hence the one-time effect of a campaign is diluted and entangled with several different effects originated with the set of campaigns which are triggered by the overall treatment policy definition for that given customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A direct approach to simulate a set of customers transactional behaviour is to simulate the purchase process as a mixture of a Bernoulli and a continous rv (log-normal for instance). First each customer will be characterized by a given purchase probability, then the number of valid transactions can be modelled as a nubmer of repeated Bernoulli trials (a Binomial rv), finally the observed purchased amounts will be modelled as the product of this bernoulli rv and the defined continous rv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Number of Observations\n",
    "SIZE = 10000\n",
    "\n",
    "# Purchase Behaviour Number of valid transactions\n",
    "n, p = 1, 0.2\n",
    "purchase_prob = np.random.binomial(n, p, SIZE)\n",
    "\n",
    "# Number of valid transactions\n",
    "N = 3\n",
    "n_trx = purchase_prob * N\n",
    "\n",
    "# Purchase Amounts\n",
    "mu, sigma = 1, 1\n",
    "purchase_amounts = np.random.lognormal(mu, sigma, SIZE)\n",
    "\n",
    "# Purchase client vector (ie: total amount spent by a given customer)\n",
    "total_spent_amount = n_trx * purchase_amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets simulate more exotic transactional features at a customers level, namely de number of units purchased. Lets assume this feature follows a Poisson distribution for every valid transaction generated by a given customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of units per customer\n",
    "n_units = np.random.poisson(4, SIZE)\n",
    "total_n_units = n_trx * n_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can generate some customer-level descriptive features such as age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.random.choice(a=range(18,70), size=size)\n",
    "gender = np.random.choice(a=range(2), size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consolidate the DGP into a pandas DataFrame for readibilty purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_df = pd.DataFrame({'gender': gender,\n",
    "                       'age': age,\n",
    "                       'purchase_flag': purchase_prob, \n",
    "                       'total_purchase_amt':total_spent_amount, \n",
    "                       'total_n_trx':n_trx, \n",
    "                       'total_n_units':total_n_units})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Now lets add average treatment effect incrementals as incrementals observed in Treatment/Control groups! #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically in an A/B testing or RCT (such as the one in defined by a RCT mkting campaign) one would expect to observe certain effects of the treatment in a set of transactional features, in order to encode this into our DGP we'll need to randomly select treatment/control groups and define an expected incremental ATE (avg. treatment effect). This is easy to do in a toy-example like this one however in a real-world application observed incremental effects are often diluted and is hard to pick up true signal amidst all the inherent noise present on a marketing campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different approaches to simulate incremental ATE, a direct approach (perhaps näive) is to simulate two groups of customer, one with a baseline set of simulation parameters and the other one with a set of parameters with the incremental effect already encoded into them.\n",
    "For simplicity lets assume we only observe an incremental ATE in the purchase rate for a given treatment policy, for this toy example let's assume the observed ATE post-treatment increases from 20% to 22%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Number of Observations\n",
    "SIZE = 10000\n",
    "\n",
    "# Purchase Behaviour Number of valid transactions\n",
    "n, p = 1, 0.22\n",
    "purchase_prob = np.random.binomial(n, p, SIZE)\n",
    "\n",
    "# Number of valid transactions\n",
    "N = 3\n",
    "n_trx = purchase_prob * N\n",
    "\n",
    "# Purchase Amounts\n",
    "mu, sigma = 1, 1\n",
    "purchase_amounts = np.random.lognormal(mu, sigma, SIZE)\n",
    "\n",
    "# Purchase client vector (ie: total amount spent by a given customer)\n",
    "total_spent_amount = n_trx * purchase_amounts\n",
    "\n",
    "# Total number of units per customer\n",
    "n_units = np.random.poisson(4, SIZE)\n",
    "total_n_units = n_trx * n_units\n",
    "\n",
    "age = np.random.choice(a=range(18,70), size=size)\n",
    "gender = np.random.choice(a=range(2), size=size)\n",
    "\n",
    "trx_df_gt = pd.DataFrame({'gender': gender,\n",
    "                       'age': age,\n",
    "                       'purchase_flag': purchase_prob, \n",
    "                       'total_purchase_amt':total_spent_amount, \n",
    "                       'total_n_trx':n_trx, \n",
    "                       'total_n_units':total_n_units})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compare both groups to check if the purchase rate is indeed different between both groups of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02049999999999999"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trx_df_gt.purchase_flag.mean() - trx_df.purchase_flag.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets wrap all up in a convenient set of functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sim_control_group(base_dict, gt_gc_ratio, inc_ate = 0):\n",
    "    # Reproducibility\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    ### BASELINE GROUP ###\n",
    "    # sim_params\n",
    "    SIZE, p, N = round(base_dict['sample_size']*(gt_gc_ratio)), base_dict['purchase_rate'] + inc_ate, base_dict['avg_valid_transactions'] \n",
    "    mu, sigma = base_dict['avg_purchase_amt'], 1\n",
    "    m = base_dict['avg_n_units']\n",
    "    \n",
    "    # Purchase Behaviour Number of valid transactions\n",
    "    purchase_prob = np.random.binomial(1.0, p, SIZE)\n",
    "    # Number of valid transactions\n",
    "    n_trx = purchase_prob * N\n",
    "    # Purchase Amounts\n",
    "    purchase_amounts = np.random.lognormal(mu, sigma, SIZE)\n",
    "    # Purchase client vector (ie: total amount spent by a given customer)\n",
    "    total_spent_amount = n_trx * purchase_amounts\n",
    "\n",
    "    # Total number of units per customer\n",
    "    n_units = np.random.poisson(m, SIZE)\n",
    "    total_n_units = n_trx * n_units\n",
    "    \n",
    "    # Descriptive features \n",
    "    age = np.random.choice(a=range(18,70), size=SIZE)\n",
    "    gender = np.random.choice(a=range(2), size=SIZE)\n",
    "    \n",
    "    # group flag\n",
    "    _df_group = pd.DataFrame({\n",
    "                           'gender': gender,\n",
    "                           'age': age,\n",
    "                           'purchase_flag': purchase_prob, \n",
    "                           'total_purchase_amt':total_spent_amount, \n",
    "                           'total_n_trx':n_trx, \n",
    "                           'total_n_units':total_n_units\n",
    "                            })\n",
    "    _df_group['group'] = 0.0\n",
    "    return _df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sim_treatment_group(base_dict, gt_gc_ratio, inc_ate = 0.02):\n",
    "    \n",
    "    _df_group = _sim_control_group(base_dict, gt_gc_ratio = 1-gt_gc_ratio, inc_ate = inc_ate)\n",
    "    _df_group['group'] = 1.0\n",
    "    return _df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emm_campaign_sim(base_dict, inc_ate, gt_gc_ratio):\n",
    "    _df_gc = _sim_control_group(base_dict, gt_gc_ratio, inc_ate = 0.0)\n",
    "    _df_gt = _sim_treatment_group(base_dict, gt_gc_ratio, inc_ate = 0.02)\n",
    "    \n",
    "    return pd.concat([_df_gc, _df_gt], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>purchase_flag</th>\n",
       "      <th>total_purchase_amt</th>\n",
       "      <th>total_n_trx</th>\n",
       "      <th>total_n_units</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>6.14398</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  purchase_flag  total_purchase_amt  total_n_trx  \\\n",
       "0          1   38              0             0.00000            0   \n",
       "1          1   33              0             0.00000            0   \n",
       "2          1   65              0             0.00000            0   \n",
       "3          1   50              0             0.00000            0   \n",
       "4          0   53              0             0.00000            0   \n",
       "...      ...  ...            ...                 ...          ...   \n",
       "6995       0   45              0             0.00000            0   \n",
       "6996       0   68              1             6.14398            3   \n",
       "6997       0   59              0             0.00000            0   \n",
       "6998       1   64              0             0.00000            0   \n",
       "6999       0   69              0             0.00000            0   \n",
       "\n",
       "      total_n_units  group  \n",
       "0                 0    0.0  \n",
       "1                 0    0.0  \n",
       "2                 0    0.0  \n",
       "3                 0    0.0  \n",
       "4                 0    0.0  \n",
       "...             ...    ...  \n",
       "6995              0    1.0  \n",
       "6996             12    1.0  \n",
       "6997              0    1.0  \n",
       "6998              0    1.0  \n",
       "6999              0    1.0  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {\"sample_size\":10000, \"purchase_rate\": 0.2, \"avg_valid_transactions\": 3, \"avg_purchase_amt\": 1.5, \"avg_n_units\":4}\n",
    "emm_campaign_sim(base_dict = params_dict, inc_ate = 0.03, gt_gc_ratio = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final thought is quite straight forward to modify these simple functions in order to simulate incrementals in the different busniess metrics that we've defined (total spents amounts, total number of units purchased, total number of valid transacionts, etc...).\n",
    "\n",
    "Moreover is a very good excercise to modify these and observe how the incremental ATE are modified when several business metrics change at the same time, which is less näive than assuming univariate changes due to treatment policies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
